# -*- coding: utf-8 -*-
"""Consolidado m9

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hVFc7mXJ1DQWcekzGqS1zKC3graHPx5P
"""

!pip install pyspark

from pyspark.sql import SparkSession
from pyspark.sql.functions import col, count, desc
from pyspark.ml.feature import VectorAssembler
from pyspark.ml.classification import LogisticRegression
from pyspark.ml.evaluation import BinaryClassificationEvaluator
from google.colab import drive

drive.mount('/content/drive')

spark = SparkSession.builder.appName("MigracionesM9").getOrCreate()

df = spark.read.csv("/content/drive/MyDrive/PorfolioBASEDATOS/M9/migraciones.csv", header=True, inferSchema=True)

df.show(5, truncate=False)
df.printSchema()
df.describe().show()

rdd = df.rdd
print("Ejemplo de RDD:", rdd.take(3))
rdd_filtrado = rdd.filter(lambda x: x['Origen'] == "Chile")
print("Migraciones desde Chile:", rdd_filtrado.count())
rdd_map = rdd.map(lambda x: (x['Origen'], x['Destino']))
print(rdd_map.take(5))
rdd_flat = rdd.flatMap(lambda x: str(x['Razón']).split(","))
print(rdd_flat.take(10))
print("Cantidad total de registros:", rdd.count())

df.filter(col("Origen") == "Argentina").show(5)
df.groupBy("Destino").count().orderBy(desc("count")).show(5)
df.write.mode("overwrite").parquet("/content/migraciones_parquet")

df.createOrReplaceTempView("migraciones")
spark.sql("SELECT `Origen`, COUNT(*) as total FROM migraciones GROUP BY `Origen` ORDER BY total DESC LIMIT 5").show()
spark.sql("SELECT `Destino`, COUNT(*) as total FROM migraciones GROUP BY `Destino` ORDER BY total DESC LIMIT 5").show()
spark.sql("SELECT `Razón`, COUNT(*) as total FROM migraciones GROUP BY `Razón` ORDER BY total DESC").show(5)

feature_cols = ["PIB_Origen","PIB_Destino","Tasa_Desempleo_Origen","Tasa_Desempleo_Destino","Nivel_Educativo_Origen","Nivel_Educativo_Destino","Población_Origen","Población_Destino"]
assembler = VectorAssembler(inputCols=feature_cols, outputCol="features")
df_ml = assembler.transform(df.na.drop(subset=feature_cols))
df_ml = df_ml.withColumn("label", (col("Año") >= 2017).cast("integer"))
final_data = df_ml.select("features", "label")

train, test = final_data.randomSplit([0.7, 0.3], seed=42)
lr = LogisticRegression(featuresCol="features", labelCol="label")
model = lr.fit(train)
predictions = model.transform(test)
evaluator = BinaryClassificationEvaluator(labelCol="label")
print("Área bajo curva ROC:", evaluator.evaluate(predictions))